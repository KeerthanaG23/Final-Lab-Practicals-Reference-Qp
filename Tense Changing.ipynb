{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2c9941d",
   "metadata": {},
   "source": [
    "#### RULE BASED APPROCH TO A BASE CASE PROBLEM - CONVERT PRESENT CONTINOUS TENSE TO SIMPLE PRESENT TENSE AND FURTHER ENHANCING IT TO OTHER TENSES ASWELL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a660d2",
   "metadata": {},
   "source": [
    "##### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b2719635",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/nlplab3/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize as wt\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lem = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73cd0113",
   "metadata": {},
   "source": [
    "#### Tokenising the sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ac9a16b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_sent = 'Harry Potter is coming to Hogwarts'\n",
    "cont_sent_token = wt(cont_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "adc26abb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Harry', 'Potter', 'is', 'coming', 'to', 'Hogwarts']\n"
     ]
    }
   ],
   "source": [
    "print(cont_sent_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a506e96",
   "metadata": {},
   "source": [
    "### Checking the POS Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f1623e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_sent_tag = nltk.pos_tag(cont_sent_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "51a198b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Harry', 'NNP'), ('Potter', 'NNP'), ('is', 'VBZ'), ('coming', 'VBG'), ('to', 'TO'), ('Hogwarts', 'VB')]\n"
     ]
    }
   ],
   "source": [
    "print(cont_sent_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d432d700",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package tagsets to /home/nlplab3/nltk_data...\n",
      "[nltk_data]   Package tagsets is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('tagsets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "39ff50c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NNP: noun, proper, singular\n",
      "    Motown Venneboerger Czestochwa Ranzer Conchita Trumplane Christos\n",
      "    Oceanside Escobar Kreisler Sawyer Cougar Yvette Ervin ODI Darryl CTCA\n",
      "    Shannon A.K.C. Meltex Liverpool ...\n"
     ]
    }
   ],
   "source": [
    "nltk.help.upenn_tagset('NNP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "602bb612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VBZ: verb, present tense, 3rd person singular\n",
      "    bases reconstructs marks mixes displeases seals carps weaves snatches\n",
      "    slumps stretches authorizes smolders pictures emerges stockpiles\n",
      "    seduces fizzes uses bolsters slaps speaks pleads ...\n"
     ]
    }
   ],
   "source": [
    "nltk.help.upenn_tagset('VBZ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1bd843b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VBG: verb, present participle or gerund\n",
      "    telegraphing stirring focusing angering judging stalling lactating\n",
      "    hankerin' alleging veering capping approaching traveling besieging\n",
      "    encrypting interrupting erasing wincing ...\n"
     ]
    }
   ],
   "source": [
    "nltk.help.upenn_tagset('VBG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "23ad6d90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TO: \"to\" as preposition or infinitive marker\n",
      "    to\n"
     ]
    }
   ],
   "source": [
    "nltk.help.upenn_tagset('TO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "492fa70d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VB: verb, base form\n",
      "    ask assemble assess assign assume atone attention avoid bake balkanize\n",
      "    bank begin behold believe bend benefit bevel beware bless boil bomb\n",
      "    boost brace break bring broil brush build ...\n"
     ]
    }
   ],
   "source": [
    "nltk.help.upenn_tagset('VB')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a34f17",
   "metadata": {},
   "source": [
    "### Lemmatizing the verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "68e73999",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'be'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lem.lemmatize(\"are\", pos=\"v\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ca78f115",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verb_to_wordnet(verb_tag):\n",
    "    if verb_tag.startswith('V') or verb_tag.startswith('JJ'):\n",
    "        return 'v'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1d88dd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_sent_lem = []\n",
    "for i in cont_sent_tag:\n",
    "    wordnet_verb = verb_to_wordnet(i[1])\n",
    "    \n",
    "    if wordnet_verb is not None:\n",
    "        cont_sent_lem.append(lem.lemmatize(i[0], wordnet_verb))\n",
    "    else:\n",
    "        cont_sent_lem.append(i[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ce0c1253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Harry', 'Potter', 'be', 'come', 'to', 'Hogwarts']\n"
     ]
    }
   ],
   "source": [
    "print(cont_sent_lem)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1ea42e",
   "metadata": {},
   "source": [
    "### Dependency Parsing approach - either syntaction parsing or semantic parsing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f099d1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "926f509b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"fcea8fb89f2e4977b60045dfbab61321-0\" class=\"displacy\" width=\"1100\" height=\"312.0\" direction=\"ltr\" style=\"max-width: none; height: 312.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Harry</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">Potter</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">is</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">coming</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">to</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">Hogwarts</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-fcea8fb89f2e4977b60045dfbab61321-0-0\" stroke-width=\"2px\" d=\"M70,177.0 C70,89.5 220.0,89.5 220.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-fcea8fb89f2e4977b60045dfbab61321-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,179.0 L62,167.0 78,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-fcea8fb89f2e4977b60045dfbab61321-0-1\" stroke-width=\"2px\" d=\"M245,177.0 C245,2.0 575.0,2.0 575.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-fcea8fb89f2e4977b60045dfbab61321-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M245,179.0 L237,167.0 253,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-fcea8fb89f2e4977b60045dfbab61321-0-2\" stroke-width=\"2px\" d=\"M420,177.0 C420,89.5 570.0,89.5 570.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-fcea8fb89f2e4977b60045dfbab61321-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M420,179.0 L412,167.0 428,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-fcea8fb89f2e4977b60045dfbab61321-0-3\" stroke-width=\"2px\" d=\"M595,177.0 C595,89.5 745.0,89.5 745.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-fcea8fb89f2e4977b60045dfbab61321-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M745.0,179.0 L753.0,167.0 737.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-fcea8fb89f2e4977b60045dfbab61321-0-4\" stroke-width=\"2px\" d=\"M770,177.0 C770,89.5 920.0,89.5 920.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-fcea8fb89f2e4977b60045dfbab61321-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M920.0,179.0 L928.0,167.0 912.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "doc = nlp('Harry Potter is coming to Hogwarts')\n",
    "displacy.render(doc,style=\"dep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "03a01c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Harry compound 1 Potter\n",
      "1 Potter nsubj 3 coming\n",
      "2 is aux 3 coming\n",
      "3 coming ROOT 3 coming\n",
      "4 to prep 3 coming\n",
      "5 Hogwarts pobj 4 to\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.i, token, token.dep_, token.head.i, token.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1ce07b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "95ba9155",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"37adefd6935a4bfe9d49e49ec14c0fa5-0\" class=\"displacy\" width=\"950\" height=\"287.0\" direction=\"ltr\" style=\"max-width: none; height: 287.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Harry</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"200\">Potter</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"200\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"350\">is</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"350\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"500\">coming</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"500\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"650\">to</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"650\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"800\">Hogwarts</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"800\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-37adefd6935a4bfe9d49e49ec14c0fa5-0-0\" stroke-width=\"2px\" d=\"M62,152.0 62,127.0 197.0,127.0 197.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-37adefd6935a4bfe9d49e49ec14c0fa5-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M62,154.0 L58,146.0 66,146.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-37adefd6935a4bfe9d49e49ec14c0fa5-0-1\" stroke-width=\"2px\" d=\"M212,152.0 212,102.0 500.0,102.0 500.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-37adefd6935a4bfe9d49e49ec14c0fa5-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M212,154.0 L208,146.0 216,146.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-37adefd6935a4bfe9d49e49ec14c0fa5-0-2\" stroke-width=\"2px\" d=\"M362,152.0 362,127.0 497.0,127.0 497.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-37adefd6935a4bfe9d49e49ec14c0fa5-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M362,154.0 L358,146.0 366,146.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-37adefd6935a4bfe9d49e49ec14c0fa5-0-3\" stroke-width=\"2px\" d=\"M512,152.0 512,127.0 647.0,127.0 647.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-37adefd6935a4bfe9d49e49ec14c0fa5-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M647.0,154.0 L651.0,146.0 643.0,146.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-37adefd6935a4bfe9d49e49ec14c0fa5-0-4\" stroke-width=\"2px\" d=\"M662,152.0 662,127.0 797.0,127.0 797.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-37adefd6935a4bfe9d49e49ec14c0fa5-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M797.0,154.0 L801.0,146.0 793.0,146.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(doc, style='dep', options={'compact': True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fd51d2cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'object of preposition'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain('pobj')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1b28dddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from beautifultable import BeautifulTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0a0ea752",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = BeautifulTable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b07fb87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "table.columns.header = ['text','POS','TAG','Explain_tag','Dep','Shape','is_alpha','is_stop']\n",
    "for token in doc:\n",
    "    table.rows.append([token.text,token.pos_,token.tag_,spacy.explain(token.tag_),token.dep_,token.shape_,token.is_alpha,token.is_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3e00af43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+-----+--------------------------+------+-------+------+------+\n",
      "| text |   POS   | TAG |       Explain_tag        | Dep  | Shape | is_a | is_s |\n",
      "|      |         |     |                          |      |       | lpha | top  |\n",
      "+------+---------+-----+--------------------------+------+-------+------+------+\n",
      "| Harr |  PROPN  | NNP |  noun, proper singular   | comp | Xxxxx |  1   |  0   |\n",
      "|  y   |         |     |                          | ound |       |      |      |\n",
      "+------+---------+-----+--------------------------+------+-------+------+------+\n",
      "| Pott |  PROPN  | NNP |  noun, proper singular   | nsub | Xxxxx |  1   |  0   |\n",
      "|  er  |         |     |                          |  j   |       |      |      |\n",
      "+------+---------+-----+--------------------------+------+-------+------+------+\n",
      "|  is  |   AUX   | VBZ | verb, 3rd person singula | aux  |  xx   |  1   |  1   |\n",
      "|      |         |     |        r present         |      |       |      |      |\n",
      "+------+---------+-----+--------------------------+------+-------+------+------+\n",
      "| comi |  VERB   | VBG | verb, gerund or present  | ROOT | xxxx  |  1   |  0   |\n",
      "|  ng  |         |     |        participle        |      |       |      |      |\n",
      "+------+---------+-----+--------------------------+------+-------+------+------+\n",
      "|  to  |   ADP   | IN  | conjunction, subordinati | prep |  xx   |  1   |  1   |\n",
      "|      |         |     |    ng or preposition     |      |       |      |      |\n",
      "+------+---------+-----+--------------------------+------+-------+------+------+\n",
      "| Hogw |  NOUN   | NNS |       noun, plural       | pobj | Xxxxx |  1   |  0   |\n",
      "| arts |         |     |                          |      |       |      |      |\n",
      "+------+---------+-----+--------------------------+------+-------+------+------+\n"
     ]
    }
   ],
   "source": [
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71393947",
   "metadata": {},
   "source": [
    "#### Correcting singularity and plurality of verbs according to the subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "91cd09bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_singular_plural(cont_sent_tag, cont_sent_lem):\n",
    "    index = 0\n",
    "    for i in range(len(cont_sent_lem)):\n",
    "        if cont_sent_lem[i] == 'be':\n",
    "            index = i\n",
    "            if 'not' in cont_sent_lem:\n",
    "                pos_neg = 'neg'\n",
    "            else:\n",
    "                pos_neg = 'pos'\n",
    "        else:\n",
    "            pos_neg = 'pos' if cont_sent_tag[index - 1][1] in ['NN', 'NNP', 'JJ'] or cont_sent_tag[index - 1][0].capitalize() in ['He', 'She', 'It'] else 'neg'\n",
    "            \n",
    "    if pos_neg == 'pos':\n",
    "        if cont_sent_lem[index + 1][-1] in ['o', 's', 'z'] or cont_sent_lem[index + 1][-2:] in ['ch', 'sh', 'x']:\n",
    "            cont_sent_lem[index + 1] += 'es'\n",
    "        elif cont_sent_lem[index + 1][-1] == 'y':\n",
    "            if cont_sent_lem[index + 1][-2] not in ['a', 'e', 'i', 'o', 'u']:\n",
    "                cont_sent_lem[index + 1] = cont_sent_lem[index + 1][:-1] + 'ies'\n",
    "            else:\n",
    "                cont_sent_lem[index + 1] += 's'\n",
    "        elif cont_sent_lem[index + 1] == 'have':\n",
    "            cont_sent_lem[index + 1] = 'has'\n",
    "        else:\n",
    "            cont_sent_lem[index + 1] += 's'\n",
    "        cont_sent_lem.remove('be')\n",
    "    else:\n",
    "        cont_sent_lem = ['does' if word == 'be' else word for word in cont_sent_lem]\n",
    "        \n",
    "    return cont_sent_lem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "686cab4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prescont_to_simpress(prescont):\n",
    "    \n",
    "    # Tokenizing\n",
    "    cont_sent_token = wt(prescont)\n",
    "    cont_sent_tag = nltk.pos_tag(cont_sent_token)\n",
    "    \n",
    "    # Lemmatizing\n",
    "    cont_sent_lem = []\n",
    "    for i in cont_sent_tag:\n",
    "        wordnet_verb = verb_to_wordnet(i[1])\n",
    "    \n",
    "        if wordnet_verb is not None:\n",
    "            cont_sent_lem.append(lem.lemmatize(i[0], wordnet_verb))\n",
    "        else:\n",
    "            cont_sent_lem.append(i[0])\n",
    "       \n",
    "    # Correcting singular and plural\n",
    "    cont_sent_lem = correct_singular_plural(cont_sent_tag, cont_sent_lem)\n",
    "    \n",
    "    #  tense form\n",
    "    print(' '.join(cont_sent_lem))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "ce711769",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"23f9f939b62f47929845263bc345ff62-0\" class=\"displacy\" width=\"1100\" height=\"312.0\" direction=\"ltr\" style=\"max-width: none; height: 312.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">She</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">is</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">studying</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">for</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">the</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">exam</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-23f9f939b62f47929845263bc345ff62-0-0\" stroke-width=\"2px\" d=\"M70,177.0 C70,2.0 400.0,2.0 400.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-23f9f939b62f47929845263bc345ff62-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,179.0 L62,167.0 78,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-23f9f939b62f47929845263bc345ff62-0-1\" stroke-width=\"2px\" d=\"M245,177.0 C245,89.5 395.0,89.5 395.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-23f9f939b62f47929845263bc345ff62-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M245,179.0 L237,167.0 253,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-23f9f939b62f47929845263bc345ff62-0-2\" stroke-width=\"2px\" d=\"M420,177.0 C420,89.5 570.0,89.5 570.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-23f9f939b62f47929845263bc345ff62-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M570.0,179.0 L578.0,167.0 562.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-23f9f939b62f47929845263bc345ff62-0-3\" stroke-width=\"2px\" d=\"M770,177.0 C770,89.5 920.0,89.5 920.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-23f9f939b62f47929845263bc345ff62-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M770,179.0 L762,167.0 778,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-23f9f939b62f47929845263bc345ff62-0-4\" stroke-width=\"2px\" d=\"M595,177.0 C595,2.0 925.0,2.0 925.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-23f9f939b62f47929845263bc345ff62-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M925.0,179.0 L933.0,167.0 917.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "doc = nlp('She is studying for the exam')\n",
    "displacy.render(doc,style=\"dep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "840b57fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "She studies for the exam\n"
     ]
    }
   ],
   "source": [
    "prescont_to_simpress(\"She is studying for the exam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "27570bd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An Indian arrives in India\n",
      "South Africans does win the match\n",
      "He waits for the bus\n",
      "The king kisses the queen gently\n",
      "Bees does buzz around the honeycomb\n",
      "Parrots does fly around the village peacefully\n",
      "A carpenter builds a bookcase\n",
      "We does enjoy ourselves\n",
      "The pianist plays Fur Elise softly\n",
      "Flowers does bloom in the morning\n",
      "A tree falls down in the storm\n",
      "My cousin goes to school on a bicycle\n"
     ]
    }
   ],
   "source": [
    "prescont_to_simpress(\"An Indian is arriving in India\")\n",
    "prescont_to_simpress(\"South Africans are winning the match\")\n",
    "prescont_to_simpress(\"He is waiting for the bus\")\n",
    "prescont_to_simpress(\"The king is kissing the queen gently\")\n",
    "prescont_to_simpress(\"Bees are buzzing around the honeycomb\")\n",
    "prescont_to_simpress(\"Parrots are flying around the village peacefully\")\n",
    "prescont_to_simpress(\"A carpenter is building a bookcase\")\n",
    "prescont_to_simpress(\"We are enjoying ourselves\")\n",
    "prescont_to_simpress(\"The pianist is playing Fur Elise softly\")\n",
    "prescont_to_simpress(\"Flowers are blooming in the morning\")\n",
    "prescont_to_simpress(\"A tree is falling down in the storm\")\n",
    "prescont_to_simpress(\"My cousin is going to school on a bicycle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "8431bca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "John nots watch TV\n"
     ]
    }
   ],
   "source": [
    "prescont_to_simpress(\"John is not watching TV\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "cffff6d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tense: Present\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Load the SpaCy English model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def identify_tense(sentence):\n",
    "    # Parse the sentence using SpaCy\n",
    "    doc = nlp(sentence)\n",
    "    \n",
    "    # Extract the tense from the parsed sentence\n",
    "    tense = None\n",
    "    for token in doc:\n",
    "        if token.tag_ == 'VBD':\n",
    "            tense = 'Past'\n",
    "        elif token.tag_ == 'VBP':\n",
    "            tense = 'Present'\n",
    "        elif token.tag_ == 'VBZ':\n",
    "            tense = 'Present'\n",
    "        elif token.tag_ == 'VBG':\n",
    "            tense = 'Present Continuous'\n",
    "        elif token.tag_ == 'VBN':\n",
    "            tense = 'Past Participle'\n",
    "    \n",
    "    return tense\n",
    "\n",
    "# Example usage\n",
    "sentence = \"He eat apples.\"\n",
    "print(\"Tense:\", identify_tense(sentence))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "f9a4db77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted tense: Past\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Sample dataset with labeled sentences and their corresponding tenses\n",
    "training_data = [\n",
    "    (\"He eats apples.\", \"Present\"),\n",
    "    (\"He ate apples.\", \"Past\"),\n",
    "    (\"He is eating apples.\", \"Present Continuous\"),\n",
    "    (\"He has eaten apples.\", \"Past Participle\"),\n",
    "]\n",
    "\n",
    "# Preparing training data\n",
    "X_train = [sentence for sentence, _ in training_data]\n",
    "y_train = [tense for _, tense in training_data]\n",
    "\n",
    "# Define a simple pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('vectorizer', CountVectorizer()),  # Convert text to numerical features\n",
    "    ('classifier', SVC())  # Classifier for tense prediction\n",
    "])\n",
    "\n",
    "# Train the pipeline\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Function to predict tense of a new sentence\n",
    "def predict_tense(sentence):\n",
    "    predicted_tense = pipeline.predict([sentence])\n",
    "    return predicted_tense[0]\n",
    "\n",
    "# Test the model\n",
    "test_sentence = \"i ate orange.\"\n",
    "predicted_tense = predict_tense(test_sentence)\n",
    "print(\"Predicted tense:\", predicted_tense)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001dea50",
   "metadata": {},
   "source": [
    "### Identification of the tense - PAST TENSE EXCLUSIVELY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1eca62a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "def detect_past_sentece(sentence):\n",
    "    sent = list(nlp(sentence).sents)[0]\n",
    "    return (\n",
    "        sent.root.tag_ == \"VBD\" or\n",
    "        any(w.dep_ == \"aux\" and w.tag_ == \"VBD\" for w in sent.root.children))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "498d2a23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The man asked what I was doing there.\n"
     ]
    }
   ],
   "source": [
    "# Importing Required libraries\n",
    "\n",
    "import spacy  # Spacy for text preprocessing\n",
    "import pyinflect  # A python module for word inflections that works as a spaCy extension.\n",
    "\n",
    "# Load small english model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Parse text through the 'nlp' model\n",
    "text = \"The man asks what I am doing there.\"\n",
    "doc = nlp(text)\n",
    "\n",
    "def past_tensifier(doc, text):\n",
    "    '''\n",
    "    function to convert any type of sentence into past tense sentence.\n",
    "    '''\n",
    "    for i in range(len(doc)):\n",
    "        token = doc[i]\n",
    "        if token.tag_ in ['VBP', 'VBZ']:\n",
    "            text = text.replace(token.text, token._.inflect(\"VBD\"))\n",
    "    return text\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    past_sentence = past_tensifier(doc, text)\n",
    "    print(past_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "4ed44138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting pyinflect\n",
      "  Downloading pyinflect-0.5.1-py3-none-any.whl (703 kB)\n",
      "\u001b[K     |████████████████████████████████| 703 kB 17.6 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: pyinflect\n",
      "Successfully installed pyinflect-0.5.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyinflect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "edb9975f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detect_past_sentece(\"she was shocked\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "cabff314",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/nlplab3/nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original word: ate\n",
      "Lemma: eat\n",
      "Past forms: eat\n",
      "i e an apple .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/nlplab3/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to /home/nlplab3/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Download required NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Function to change tense using NLTK\n",
    "def change_tense_nltk(text, to_tense):\n",
    "    # Tokenize the text into sentences\n",
    "    sentences = sent_tokenize(text)\n",
    "    out = []\n",
    "    for sentence in sentences:\n",
    "        tokens = nltk.word_tokenize(sentence)\n",
    "        tagged_tokens = pos_tag(tokens)\n",
    "        for word, tag in tagged_tokens:\n",
    "            if tag.startswith('VB'):  # If word is a verb\n",
    "                lemma = WordNetLemmatizer().lemmatize(word, 'v')\n",
    "                print(\"Original word:\", word)\n",
    "                print(\"Lemma:\", lemma)\n",
    "                if to_tense == 'present':\n",
    "                    # Check if present tense form exists in WordNet\n",
    "                    present_forms = wordnet.morphy(lemma, wordnet.VERB)\n",
    "                    print(\"Present forms:\", present_forms)\n",
    "                    if present_forms:\n",
    "                        out.append(present_forms[0])\n",
    "                    else:\n",
    "                        out.append(lemma)\n",
    "                elif to_tense == 'past':\n",
    "                    # Check if past tense form exists in WordNet\n",
    "                    past_forms = wordnet.morphy(lemma, wordnet.VERB)\n",
    "                    print(\"Past forms:\", past_forms)\n",
    "                    if past_forms:\n",
    "                        out.append(past_forms[0])\n",
    "                    else:\n",
    "                        out.append(lemma)\n",
    "                elif to_tense == 'future':\n",
    "                    out.append('will ' + lemma)\n",
    "            else:\n",
    "                out.append(word)\n",
    "    return ' '.join(out)\n",
    "\n",
    "# Example usage\n",
    "text = \"i ate an apple.\"\n",
    "print(change_tense_nltk(text, 'past'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b22c07cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alice be begin to get very tired of sit by her sister on the bank .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/nlplab3/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/nlplab3/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to /home/nlplab3/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Download NLTK resources if not already downloaded\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Function to convert verb tense using NLTK\n",
    "def change_tense_nltk(text, to_tense):\n",
    "    # Tokenize the text into sentences\n",
    "    sentences = sent_tokenize(text)\n",
    "    out = []\n",
    "    for sentence in sentences:\n",
    "        tokens = nltk.word_tokenize(sentence)\n",
    "        tagged_tokens = pos_tag(tokens)\n",
    "        for word, tag in tagged_tokens:\n",
    "            if tag.startswith('VB'):  # If word is a verb\n",
    "                # Lemmatize the verb\n",
    "                lemma = WordNetLemmatizer().lemmatize(word, 'v')\n",
    "                # Convert to specified tense\n",
    "                if to_tense == 'present':\n",
    "                    out.append(lemma)  # No tense conversion needed for present tense\n",
    "                elif to_tense == 'past':\n",
    "                    # Use past tense form if available\n",
    "                    past_form = nltk.corpus.wordnet.morphy(lemma, nltk.corpus.wordnet.VERB)\n",
    "                    out.append(past_form[0] if past_form else lemma)\n",
    "                elif to_tense == 'future':\n",
    "                    out.append('will ' + lemma)  # Add \"will\" for future tense\n",
    "            else:\n",
    "                out.append(word)  # Append non-verb tokens unchanged\n",
    "    return ' '.join(out)\n",
    "\n",
    "# Example usage\n",
    "text = \"\"\n",
    "print(change_tense_nltk(text, 'present'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "98de9cec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he is bad\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Load the English language model for spaCy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Function to convert verb tense using spaCy\n",
    "def change_tense_spacy(text, to_tense):\n",
    "    # Parse the text using spaCy\n",
    "    doc = nlp(text)\n",
    "    out = []\n",
    "    \n",
    "    for token in doc:\n",
    "        # If the token is a verb and is not an auxiliary verb (e.g., \"will\")\n",
    "        if token.pos_ == 'VERB' and token.dep_ != 'aux':\n",
    "            # Convert to the specified tense\n",
    "            if to_tense == 'present':\n",
    "                # Use present tense form\n",
    "                out.append(token.lemma_)\n",
    "            elif to_tense == 'past':\n",
    "                # Use past tense form\n",
    "                out.append(token._.inflect('VBD'))\n",
    "            elif to_tense == 'future':\n",
    "                # Add \"will\" and use base form (infinitive) of the verb\n",
    "                out.append('will')\n",
    "                out.append(token.lemma_)\n",
    "        else:\n",
    "            # Append non-verb tokens unchanged\n",
    "            out.append(token.text)\n",
    "    \n",
    "    return ' '.join(out)\n",
    "\n",
    "# Example usage\n",
    "text = \"he is bad\"\n",
    "print(change_tense_spacy(text, 'present'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2b0feb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
